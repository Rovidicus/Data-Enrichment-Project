{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10e98d1-fb0e-440c-8e25-ea08878cc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# We want all columns displayed, setting output to 50 to be safe\n",
    "pd.set_option('display.max_columns',100)\n",
    "import os, time, json\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48795ec5-1e15-474b-a8f7-5e7a882be500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['API Key', 'Access Token'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/Rovidicus/.secret/tmdb_api.json','r') as f:\n",
    "    login=json.load(f)\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db7070d-2add-4791-9223-db73201a66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY = login['API Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0b1d75-9fe8-4174-b2b0-7d4e5aa7cee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El tango del viudo y su espejo deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0096056</td>\n",
       "      <td>movie</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                                       primaryTitle  \\\n",
       "0  tt0035423     movie                                     Kate & Leopold   \n",
       "1  tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "2  tt0069049     movie                         The Other Side of the Wind   \n",
       "3  tt0088751     movie                                  The Naked Monster   \n",
       "4  tt0096056     movie                               Crime and Punishment   \n",
       "\n",
       "                               originalTitle  isAdult  startYear  endYear  \\\n",
       "0                             Kate & Leopold        0     2001.0      NaN   \n",
       "1  El tango del viudo y su espejo deformante        0     2020.0      NaN   \n",
       "2                 The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                          The Naked Monster        0     2005.0      NaN   \n",
       "4                       Crime and Punishment        0     2002.0      NaN   \n",
       "\n",
       "   runtimeMinutes                  genres  \n",
       "0             118  Comedy,Fantasy,Romance  \n",
       "1              70                   Drama  \n",
       "2             122                   Drama  \n",
       "3             100    Comedy,Horror,Sci-Fi  \n",
       "4             126                   Drama  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basics=pd.read_csv('Data/basics.csv')\n",
    "basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de703a24-c2bb-4feb-ab11-06a7061891ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'final_tmdb_data_2020.csv.gz',\n",
       " 'final_tmdb_data_2021.csv.gz',\n",
       " 'final_tmdb_data_2022.csv.gz',\n",
       " 'tmdb_api_results_2020.json',\n",
       " 'tmdb_api_results_2021.json',\n",
       " 'tmdb_api_results_2022.json',\n",
       " 'tmdb_results_postcovid.csv.gz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER=\"Data/Hypothesis_Testing/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d8e83e-3f88-485d-89f3-da5f49f93d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    movie_info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    \n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            movie_info['certification'] = c['certification']\n",
    "    return movie_info\n",
    "\n",
    "\n",
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        file_data = json.load(file)\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        file.seek(0)\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b8771e-ddcc-4f9d-94b7-6fb9df7bf2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will retreive movie data on years from the pandemic to present\n",
    "YEARS_TO_GET=list(range(2020, 2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f33468-014a-4c8a-b42a-8cb9cb032cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee8142fe92c42f0afd83f07102eafdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file Data/Hypothesis_Testing/tmdb_api_results_2020.json already exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ffe418d9a74799a55d85e48ff9b52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2020:   0%|          | 0/5010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start of OUTER loop\n",
    " for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    JSON_FILE_YEAR = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    file_exists = os.path.isfile(JSON_FILE_YEAR)\n",
    "\n",
    "    if file_exists == False:\n",
    "        print(f'Creating{JSON_FILE_YEAR} for API results for year = {YEAR}.')\n",
    "        with open (JSON_FILE_YEAR, 'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "    else:\n",
    "        print(f'The file {JSON_FILE_YEAR} already exists.')\n",
    "\n",
    "    df_year = basics.loc[basics['startYear'] == YEAR].copy()\n",
    "    movie_ids = df_year['tconst']\n",
    "        \n",
    "        # Create an empty list to store movie information\n",
    "    movie_info_list = []\n",
    "    errors=[]    \n",
    "        # Iterate over movie IDs for the current year\n",
    "    for movie_id in tqdm_notebook(movie_ids, f'Movies from {YEAR}'):\n",
    "        try:\n",
    "            temp = get_movie_with_rating(movie_id)\n",
    "            movie_info_list.append(temp)\n",
    "            time.sleep(0.02)\n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "        \n",
    "        # Write the movie information to the JSON file\n",
    "    write_json(movie_info_list, JSON_FILE_YEAR)\n",
    "\n",
    "    final_year_df2 = pd.read_json(JSON_FILE_YEAR)\n",
    "    csv_fname = f'{FOLDER}final_tmdb_data_{YEAR}.csv.gz'\n",
    "    final_year_df2.to_csv(csv_fname, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f321f73-4471-4eaa-a721-07fbefaab635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# Use glob to get all filepaths that match the pattern (*=wildcard)\n",
    "tmdb_files = sorted(glob.glob(\"Data/Hypothesis_Testing/final_tmdb_data*.csv.gz\"))\n",
    "tmdb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf68fa-0ca5-4db7-8fb8-d76145498f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read_csv in a list comprehension and combine with concat to load all files\n",
    "df = pd.concat([pd.read_csv(f) for f in tmdb_files] )\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf787d56-1c6f-4c8c-ba89-9faf78a17c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final merged csv as 'tmdb_results_combined.csv.gz'\n",
    "fname = f'{FOLDER}tmdb_results_postcovid.csv.gz'\n",
    "df.to_csv(fname, compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d1b4f-deaf-4347-9aa1-3ea53f1a436f",
   "metadata": {},
   "source": [
    "1. Does the MPAA rating of a movie (G/PG/PG-13/R) affect how much revenue the movie generates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3384a-490b-4efd-8938-c9defccf5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are dealing with several variables and a numeric problem (revenue)\n",
    "# An analysis of variance (ANOVA) will be useful here\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ff043-dc56-4f41-b776-dd4dfd3aa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize our revenues per genre\n",
    "sns.barplot(df, x = 'certification', y = 'revenue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb1ca3-9f34-4314-b01f-bab3a8a92656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['certification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe865cb-d3d7-40f8-af12-0a66cf4f753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1a9f5-1aaf-4e42-bbc4-a481e1ca0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = nn.dropna(subset=['certification', 'revenue'])\n",
    "nn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb0043-10cc-4fbf-8604-a1921755a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each group needs to be separated to be analyzed.\n",
    "groups = {}\n",
    "## Loop through all unique categories\n",
    "for i in nn['certification'].unique():\n",
    "    ## Get series for group and rename\n",
    "    data = nn.loc[nn['certification']==i,'revenue'].copy()\n",
    "    \n",
    "    # save into the dictionary\n",
    "    groups[i] = data\n",
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6f100-8cec-4043-aab5-61e1b817a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running normal test on each group and confirming there are >20 in each group\n",
    "norm_results = {}\n",
    "for i, data in groups.items():\n",
    "    stat, p = stats.normaltest(data)\n",
    "    ## save the p val, test statistic, and the size of the group\n",
    "    norm_results[i] = {'n': len(data),\n",
    "                             'p':p,\n",
    "                             'test stat':stat,}\n",
    "## convert to a dataframe\n",
    "norm_results_df = pd.DataFrame(norm_results).T\n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3921b-9058-419c-900c-94945ad0b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking sig with pandas \n",
    "norm_results_df['sig'] = norm_results_df['p'] < .05 \n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99162a-a276-47a7-8635-4df93e1c92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the correct hypothesis test\n",
    "result = stats.f_oneway( *groups.values())\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50416412-bdbe-4f7d-a803-b31a31b0a6af",
   "metadata": {},
   "source": [
    "### With ANOVA giving us a significant result, we can use tukey to perform comparison tests for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368b469-abfb-4b82-90c1-f33b0ab078d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "## save the values as kg_lost and the labels to the Diet\n",
    "values = nn['revenue']\n",
    "labels = nn['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97345df6-2cae-4537-9f94-6e43f8f29cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform tukey's multiple comparison test and display the summary\n",
    "tukeys_results = pairwise_tukeyhsd(values,labels)\n",
    "tukeys_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bdca8-8533-4e58-8a46-0bc85d515630",
   "metadata": {},
   "source": [
    "##### We can see several significant results between MPAA ratings like PG-13 outperforming R, PG, NR and G. \n",
    "##### Not Rated trends poorly against PG and PG-13. While NC-17 doesn't have good revenue, the differences are not considered significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9202ff-ffb3-4cdb-9112-64e564fa6271",
   "metadata": {},
   "source": [
    "2. Do movies that are over 2.5 hours long earn more revenue than movies that are 1.5 hours long (or less)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd552c2-c63b-4663-aada-d2ba9203390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing revenue by runtime\n",
    "sns.scatterplot(df, x='runtime', y='revenue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2797c7e-907b-4f8a-9440-b036f9a80f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering films into dfs of long and short movies\n",
    "long_df = df.loc[df['runtime'] >= 150].copy()\n",
    "short_df = df.loc[df['runtime']<= 90].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86747884-a712-4805-91b2-3ffbc73627f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now defining revenue dfs\n",
    "long_r = long_df['revenue']\n",
    "short_r = short_df['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e0aa5-1d48-453d-ac4b-b3788fde1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in long film revenue\n",
    "zscores= stats.zscore(long_r)\n",
    "outliers = abs(zscores)>3\n",
    "np.sum(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698aebf0-f9ff-4087-92a0-fd380c161736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from strength group\n",
    "long_r = long_r[(np.abs(stats.zscore(long_r)) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ddc3d-6ad2-4ef0-ab89-ca2745e5289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking same for short films\n",
    "zscores= stats.zscore(short_r)\n",
    "np.sum(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d46ab0-f2f4-4002-85f3-dba898aed80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "short_r = short_r[(np.abs(stats.zscore(short_r)) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68778884-19a0-4665-8bbb-43838f04b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for equal variance\n",
    "result = stats.levene(long_r, short_r)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a968b835-d65b-43c2-a273-49b55126a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent t-test with equal_var set to False\n",
    "result = stats.ttest_ind(long_r, short_r, equal_var = False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a318f-2426-4038-8c3f-238cce51cb34",
   "metadata": {},
   "source": [
    "##### With pvalue far less than 0.05 we have a significant result and can reject null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3a69f-9a81-4433-b998-ec60f49fccdb",
   "metadata": {},
   "source": [
    "3. Do different certifications trend to different popularity numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551751ed-90ad-4119-9197-a3644b9e2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making barplot to get a glimpse at correlation\n",
    "sns.barplot(nn, x='certification', y='popularity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b909dbb-2a44-42b7-b726-c961bcbb7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There does seem to be correlations though how significant will have to be determined\n",
    "# It's another ANOVA problem with certifications so we can use our copied df to keep nulls out\n",
    "groups = {}\n",
    "## Loop through all unique categories\n",
    "for i in nn['certification'].unique():\n",
    "    ## Get series for group and rename\n",
    "    data = nn.loc[nn['certification']==i,'popularity'].copy()\n",
    "    \n",
    "    # save into the dictionary\n",
    "    groups[i] = data\n",
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea4b9a-52c7-4e83-8737-b4f223e54e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running normal test on each group and confirming there are >20 in each group\n",
    "norm_results = {}\n",
    "for i, data in groups.items():\n",
    "    stat, p = stats.normaltest(data)\n",
    "    ## save the p val, test statistic, and the size of the group\n",
    "    norm_results[i] = {'n': len(data),\n",
    "                             'p':p,\n",
    "                             'test stat':stat,}\n",
    "## convert to a dataframe\n",
    "norm_results_df = pd.DataFrame(norm_results).T\n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec72bd9-fe2f-4554-b9f4-cbaf729530d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking sig with pandas \n",
    "norm_results_df['sig'] = norm_results_df['p'] < .05 \n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb0269-e659-4ee0-afd1-b95f4f7a507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the correct hypothesis test\n",
    "result = stats.f_oneway( *groups.values())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7e400-0077-4b3e-a3b1-973b5a91cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitely significant.\n",
    "values = nn['popularity']\n",
    "# labels is same as in first problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351acefa-ced0-46ca-9b59-6dfc9cb6b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform tukey's multiple comparison test and display the summary\n",
    "tukeys_results = pairwise_tukeyhsd(values,labels)\n",
    "tukeys_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708e161-22c1-4830-99c7-dd0f5918752f",
   "metadata": {},
   "source": [
    "##### That's a lot to unpack. PG has a significant popularity boost over G, NC-17, and NR. PG-13 enjoys popularity over NC-17 and NR.\n",
    "##### G as a rating is in the middle and not significantly different except to PG. NC-17 and NR trend poorly, perhaps unsurprisingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
